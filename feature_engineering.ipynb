{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "from download_data import download_googledrive_folder\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def colored_line(x, y, c, ax, **lc_kwargs):\n",
    "    \"\"\"\n",
    "    Plot a line with a color specified along the line by a third value.\n",
    "\n",
    "    It does this by creating a collection of line segments. Each line segment is\n",
    "    made up of two straight lines each connecting the current (x, y) point to the\n",
    "    midpoints of the lines connecting the current point with its two neighbors.\n",
    "    This creates a smooth line with no gaps between the line segments.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array-like\n",
    "        The horizontal and vertical coordinates of the data points.\n",
    "    c : array-like\n",
    "        The color values, which should be the same size as x and y.\n",
    "    ax : Axes\n",
    "        Axis object on which to plot the colored line.\n",
    "    **lc_kwargs\n",
    "        Any additional arguments to pass to matplotlib.collections.LineCollection\n",
    "        constructor. This should not include the array keyword argument because\n",
    "        that is set to the color argument. If provided, it will be overridden.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.collections.LineCollection\n",
    "        The generated line collection representing the colored line.\n",
    "    \"\"\"\n",
    "    if \"array\" in lc_kwargs:\n",
    "        warnings.warn('The provided \"array\" keyword argument will be overridden')\n",
    "\n",
    "    # Default the capstyle to butt so that the line segments smoothly line up\n",
    "    default_kwargs = {\"capstyle\": \"butt\"}\n",
    "    default_kwargs.update(lc_kwargs)\n",
    "\n",
    "    # Compute the midpoints of the line segments. Include the first and last points\n",
    "    # twice so we don't need any special syntax later to handle them.\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    x_midpts = np.hstack((x[0], 0.5 * (x[1:] + x[:-1]), x[-1]))\n",
    "    y_midpts = np.hstack((y[0], 0.5 * (y[1:] + y[:-1]), y[-1]))\n",
    "\n",
    "    # Determine the start, middle, and end coordinate pair of each line segment.\n",
    "    # Use the reshape to add an extra dimension so each pair of points is in its\n",
    "    # own list. Then concatenate them to create:\n",
    "    # [\n",
    "    #   [(x1_start, y1_start), (x1_mid, y1_mid), (x1_end, y1_end)],\n",
    "    #   [(x2_start, y2_start), (x2_mid, y2_mid), (x2_end, y2_end)],\n",
    "    #   ...\n",
    "    # ]\n",
    "    coord_start = np.column_stack((x_midpts[:-1], y_midpts[:-1]))[:, np.newaxis, :]\n",
    "    coord_mid = np.column_stack((x, y))[:, np.newaxis, :]\n",
    "    coord_end = np.column_stack((x_midpts[1:], y_midpts[1:]))[:, np.newaxis, :]\n",
    "    segments = np.concatenate((coord_start, coord_mid, coord_end), axis=1)\n",
    "\n",
    "    lc = LineCollection(segments, **default_kwargs)\n",
    "    lc.set_array(c)  # set the colors of each segment\n",
    "\n",
    "    return ax.add_collection(lc)\n",
    "\n",
    "\n",
    "def plot_curve(X):\n",
    "    \"\"\"\n",
    "    Plot a curve given by the points in X.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : torch.Tensor\n",
    "        The points on the curve. Should be a 2D tensor with shape (n_points, 3).\n",
    "        each point represents a (t, x, y) value.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------- Create and show plot --------------\n",
    "    # Some arbitrary function that gives x, y, and color values\n",
    "    t = X[:, 0].numpy()\n",
    "    x = X[:, 1].numpy()\n",
    "    y = X[:, 2].numpy()\n",
    "    color = np.linspace(0, int(np.max(t)) + 1,t.size )  # color by t value\n",
    "\n",
    "    # Create a figure and plot the line on it\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    lines = colored_line(x, y, color, ax1,  cmap=\"plasma\")\n",
    "    fig1.colorbar(lines)  # add a color legend\n",
    "\n",
    "    # Set the axis limits and tick positions\n",
    "    ax1.set_xlim(np.min(x), np.max(x))\n",
    "    ax1.set_ylim(np.min(y), np.max(y))\n",
    "    # ax1.set_xticks((-1, 0, 1))\n",
    "    # ax1.set_yticks((-1, 0, 1))\n",
    "    ax1.set_title(\"worm movement\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    # list all csv files in the directory\n",
    "    csv_files = os.listdir(data_path)\n",
    "    csv_files = [f for f in csv_files if f.endswith(\".csv\")]\n",
    "\n",
    "    worms=[]\n",
    "    min_length = 9999999999\n",
    "    for worm in csv_files:\n",
    "        worm_data = np.genfromtxt(data_path+worm, delimiter=\",\", skip_header=1, dtype=np.float32)\n",
    "        min_length = min(worm_data.shape[0], min_length)\n",
    "        worms.append(worm_data)\n",
    "    return worms, min_length\n",
    "\n",
    "\n",
    "control_data,min_length1 = load_data(\"./data/Lifespan/control/\")\n",
    "drug_data,min_length2 = load_data(\"./data/Lifespan/companyDrug/\")\n",
    "min_length = min(min_length1,min_length2)\n",
    "num_control = len(control_data)\n",
    "num_drug = len(drug_data)\n",
    "\n",
    "worms = control_data + drug_data\n",
    "lifespan = np.zeros(len(worms))\n",
    "for i in range(len(worms)):\n",
    "    worm_xy = worms[i][:,[2,3]]\n",
    "    delta_xy = np.diff(worm_xy, axis=0)\n",
    "    speed = np.linalg.norm(delta_xy, axis=1)\n",
    "    inactive_frames = speed<DEATH_THRESHOLD\n",
    "    cum_inactive_frames = np.cumsum(inactive_frames, axis=0)\n",
    "    consecu_inactive = cum_inactive_frames-np.roll(cum_inactive_frames, DEATH_LENGTH, axis=0)\n",
    "    dead = consecu_inactive==(DEATH_LENGTH-1)\n",
    "    # get the first dead frame\n",
    "    res = np.where(dead)[0]\n",
    "    if res.shape[0] == 0:\n",
    "        lifespan[i] = worm_xy.shape[0]//900/4\n",
    "    else:\n",
    "        lifespan[i] = res[0]//900/4\n",
    "\n",
    "    \n",
    "    worms[i] = worms[i][:min_length]\n",
    "data = np.stack(worms, axis=0)\n",
    "t_xy = torch.tensor(data[:, :, [0,2,3]])\n",
    "xy = t_xy[:, :, 1:]\n",
    "\n",
    "x = xy\n",
    "# y = torch.tensor([0]*num_control + [1]*num_drug, dtype=torch.float32)\n",
    "y = torch.tensor(lifespan, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.2500, 19.2500, 13.7500, 16.0000, 17.7500, 17.7500, 14.2500, 15.0000,\n",
       "        14.7500, 13.0000, 15.0000, 15.0000, 14.7500,  0.5000, 12.5000, 17.5000,\n",
       "        12.2500, 18.7500, 16.7500, 13.7500, 20.7500, 12.7500, 16.5000, 17.7500])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=xy[:,:900*8].reshape(x.shape[0],-1,900,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 8, 900, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7086, 1.9527, 2.1065, 1.6648, 1.4510, 1.9013, 2.3264, 1.2639, 2.1138,\n",
       "        8.7371, 1.4162, 1.4512, 4.3873, 0.9761, 1.5847, 7.2195, 1.5256, 2.7563,\n",
       "        1.7761, 1.3338, 1.8913, 1.5563, 1.1253, 1.6555])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_frame = torch.roll(x, 1, 2) \n",
    "delta_xy = (x - last_frame)[:,:,1:,:]\n",
    "speed = torch.norm(delta_xy, dim=3)\n",
    "avg_speed_single_period = torch.nanmean(speed, dim=2)\n",
    "avg_speed = torch.nanmean(avg_speed_single_period, dim=1)\n",
    "# print(avg_speed_single_period)\n",
    "\n",
    "def avg_first_k_periods(x, k):\n",
    "    \n",
    "    avg_single_period = torch.mean(x, dim=2)\n",
    "    avg = torch.nanmean(avg_single_period[:,:k], dim=1)\n",
    "    return avg\n",
    "\n",
    "def var_single_period(x):\n",
    "    return torch.var(x, dim=2)\n",
    "     \n",
    "def var_first_k_periods(x, k):\n",
    "    avg_single_period = torch.mean(x, dim=2)\n",
    "    avg = torch.var(avg_single_period[:,:k], dim=1)\n",
    "    return avg\n",
    "\n",
    "def avg_across_periods(x,start,end):\n",
    "    avg_single_period = torch.mean(x, dim=2)\n",
    "    var = torch.nanmean(avg_single_period[:,start:end], dim=1)\n",
    "    return var\n",
    "\n",
    "# avg_speed_first_4_periods = avg_first_k_periods(speed, 4)\n",
    "avg_speed_first_4_periods = avg_speed\n",
    "avg_speed_first_4_periods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceleration = speed - torch.roll(speed, 1, 2)\n",
    "\n",
    "# avg_acc_first_2_periods = avg_first_k_periods(acceleration, 2)\n",
    "\n",
    "avg_acc = torch.nanmean(torch.nanmean(acceleration, dim=2), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8879, 0.7807, 0.9982, 0.9546, 0.9892, 0.9963, 0.9787, 0.9965, 0.9889,\n",
       "        0.9218, 0.9537, 0.9691, 0.9105, 0.7421, 0.9932, 0.9355, 0.9634, 0.9420,\n",
       "        0.9947, 0.8640, 0.8967, 0.9932, 0.9091, 0.9939])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0\n",
    "active_frames = speed > threshold\n",
    "active_time = torch.sum(active_frames, dim=2)\n",
    "# divide active_time by number of non-nan frames\n",
    "active_time = active_time / (active_frames.shape[2] - torch.sum(torch.isnan(speed), dim=2))\n",
    "avg_active_time = torch.nanmean(active_time, dim=1,dtype=torch.float32)\n",
    "\n",
    "avg_active_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharp_turn = torch.sum(torch.sum(delta_xy*torch.roll(delta_xy, 1, 2),dim=3)[:,:,2:]<0,dim=2)\n",
    "\n",
    "# divide sharp_turn by number of non-nan frames\n",
    "sharp_turn = sharp_turn / (delta_xy.shape[2] - torch.sum(torch.any(torch.isnan(delta_xy),dim=3), dim=2))\n",
    "avg_sharp_turn = torch.nanmean(sharp_turn, dim=1,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shifted = x-x[:,:,0,:].unsqueeze(2)\n",
    "rotation_angle = -torch.arctan(x_shifted[:,:,-1,1]/x_shifted[:,:,-1,0]).unsqueeze(2)\n",
    "# angles = torch.arctan(x_shifted[:,:,:,1]/x_shifted[:,:,:,0])\n",
    "# rotation_angles = end_angle - angles\n",
    "cos_rot = torch.cos(rotation_angle).unsqueeze(3)\n",
    "sin_rot = torch.sin(rotation_angle).unsqueeze(3)\n",
    "rotated_x = torch.sum(x_shifted.unsqueeze(4)*torch.cat((cos_rot, -sin_rot,sin_rot,cos_rot), dim=3).reshape(x_shifted.shape[0],x_shifted.shape[1],1,2,2),axis=4)\n",
    "\n",
    "final_x=torch.where(torch.isnan(rotated_x), x_shifted, rotated_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill nan on final x by using the next and last frame along dimension 2\n",
    "final_x_filled = torch.where(torch.isnan(final_x), torch.roll(final_x, 1, 2), final_x)\n",
    "final_x_filled = torch.where(torch.isnan(final_x_filled), torch.roll(final_x_filled, -1, 2), final_x_filled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive - HKUST Connect\\CS433\\MLProject2\\.venv\\Lib\\site-packages\\shapely\\measurement.py:261: RuntimeWarning: invalid value encountered in frechet_distance\n",
      "  return lib.frechet_distance(a, b, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[168.5555,  43.6669,      nan,      nan, 431.8122, 436.9256,  44.0135],\n",
       "        [ 56.8308,   0.9308,   3.3427,  35.1488, 158.0401, 493.9297, 405.7979],\n",
       "        [     nan,      nan, 212.3379,  78.7844, 487.1808, 542.5905, 328.4906],\n",
       "        [     nan,   9.6561,  39.0992, 154.1058, 167.5956,      nan,      nan],\n",
       "        [ 52.8693, 257.3020, 292.4625, 141.8313, 100.8104, 311.4603, 299.4502],\n",
       "        [137.8762, 157.0831, 287.4040, 140.2231,  83.1240, 230.4048, 712.6235],\n",
       "        [     nan, 113.3740, 131.1903,  70.3422,  12.1923, 169.1046, 343.7606],\n",
       "        [     nan,  43.8303,  60.3129, 333.9238, 328.2848, 303.3276, 280.7503],\n",
       "        [ 14.0989, 231.5280, 205.9086, 230.7948, 326.9601, 161.9845, 148.4532],\n",
       "        [352.1542, 416.6798, 265.9317,      nan,      nan, 292.3742, 399.4318],\n",
       "        [258.3849, 160.4782, 350.2946, 287.5157,  46.6903, 111.8296, 354.4059],\n",
       "        [454.3577, 478.5380, 373.1893, 172.0591, 286.5813, 172.0199, 171.1631],\n",
       "        [332.1151, 347.7637, 221.1542, 316.2013, 231.7091, 239.6326, 182.6966],\n",
       "        [ 23.5277,   1.4581,   1.4878,  12.4601, 355.4184, 171.4627,  33.3810],\n",
       "        [     nan,  97.5925,  99.3700,      nan,      nan,  50.6123,  43.6027],\n",
       "        [ 10.9227,  20.9168,  27.9380, 190.0424, 191.0473,  32.4521,   7.3623],\n",
       "        [134.1564, 101.1144, 147.1632, 108.9044, 282.2379, 273.9322,  91.0469],\n",
       "        [301.8991, 175.4178,  23.6830,  47.2860, 175.6067, 267.2124,   1.0638],\n",
       "        [370.2336, 335.1567, 338.1267, 358.2451, 406.7805, 186.0889, 148.4868],\n",
       "        [  4.2228,   4.2228, 171.1392, 245.1922,  89.2477,  82.3384, 297.2396],\n",
       "        [429.1430, 196.1306,  31.5388, 355.8985, 427.8089, 188.8734,  50.5618],\n",
       "        [     nan,  45.0009, 509.1162, 513.3274,  40.0800,  43.6585, 148.0952],\n",
       "        [ 78.4634,  60.9921,  72.8491,  69.6918,   7.4040,  49.2881,  57.8922],\n",
       "        [322.1432, 319.8235, 456.8021, 449.5430, 331.3724, 153.5434,  82.2210]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shapely import LineString, frechet_distance\n",
    "\n",
    "frechet_dist = torch.zeros(x.shape[0], x.shape[1]-1)\n",
    "for i in range(x.shape[0]):\n",
    "    for period in range(x.shape[1]-1):\n",
    "        frechet_dist[i][period] = frechet_distance(LineString(final_x_filled[i][period]), LineString(final_x_filled[i][period+1]))\n",
    "\n",
    "frechet_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 5])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.stack((avg_speed_first_4_periods, avg_acc, avg_active_time, avg_sharp_turn, torch.nanmean(frechet_dist,dim=1)), dim=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(features):\n",
    "    return (features - torch.mean(features, dim=0))/torch.std(features, dim=0)\n",
    "tx = normalize(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize y\n",
    "\n",
    "ty = (y - torch.mean(y))/torch.std(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix, f1_score\n\u001b[0;32m      7\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(tx, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.33\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(y_test, y_pred))\n",
      "File \u001b[1;32mc:\\Users\\danie\\OneDrive - HKUST Connect\\CS433\\MLProject2\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\OneDrive - HKUST Connect\\CS433\\MLProject2\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1231\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1221\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m   1223\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1224\u001b[0m     X,\n\u001b[0;32m   1225\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1229\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1230\u001b[0m )\n\u001b[1;32m-> 1231\u001b[0m \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;66;03m# TODO(1.7) remove multi_class\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\OneDrive - HKUST Connect\\CS433\\MLProject2\\.venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:219\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    211\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    218\u001b[0m ]:\n\u001b[1;32m--> 219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "# linear classifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tx, y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:23<00:00,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37875\n",
      "0.35925519480519486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.192431  , 0.23376084, 0.19435263, 0.1117646 , 0.26769092])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "# accuracy_scores = []\n",
    "# f1_scores = []\n",
    "# for i in tqdm(range(1000)):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(tx, y, test_size=0.33, random_state=i)\n",
    "#     clf = RandomForestClassifier(max_depth=2)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "#     f1_scores.append(f1_score(y_test, y_pred))\n",
    "\n",
    "# print(np.mean(accuracy_scores))\n",
    "# print(np.mean(f1_scores))\n",
    "clf = RandomForestClassifier(max_depth=2)\n",
    "clf.fit(X_train[:,[0]], y_train)\n",
    "y_pred = clf.predict(X_test[:,[0]])\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(f1_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "clf.feature_importances_\n",
    "\n",
    "# train accuracy\n",
    "# y_pred = clf.predict(X_train)\n",
    "# print(accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375\n",
      "0.2857142857142857\n",
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "# SVM classifier\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# train accuracy\n",
    "y_pred = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375\n",
      "0.2857142857142857\n",
      "0.625\n"
     ]
    }
   ],
   "source": [
    "# knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# train accuracy\n",
    "y_pred = clf.predict(X_train)\n",
    "print(accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tx,ty, test_size=0.33)\n",
    "\n",
    "def evaluate_regression_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.5023913383483887\n",
      "R2: -3.85640811920166\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "evaluate_regression_model(reg, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.9063017547647877\n",
      "R2: -1.9295769815962882\n"
     ]
    }
   ],
   "source": [
    "# SVR\n",
    "reg = SVR().fit(X_train, y_train)\n",
    "\n",
    "evaluate_regression_model(reg, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6998694029877301\n",
      "R2: -1.2622942991526154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.19798165, 0.08623673, 0.31376139, 0.35061783, 0.0514024 ])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "reg = RandomForestRegressor(max_depth=3).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "evaluate_regression_model(reg, X_train, y_train, X_test, y_test)\n",
    "reg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.3548211804193184\n",
      "R2: -3.3793945266779657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\OneDrive - HKUST Connect\\CS433\\MLProject2\\.venv\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# gaussian process\n",
    "kernel = 1.0 * RBF(length_scale=1.0) + WhiteKernel(noise_level=1)\n",
    "reg = GaussianProcessRegressor(kernel=kernel, random_state=0)\n",
    "\n",
    "evaluate_regression_model(reg, X_train, y_train, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.1432291391381177\n",
      "R2: -9.160337531611184\n"
     ]
    }
   ],
   "source": [
    "# neural network\n",
    "reg = MLPRegressor(random_state=1, max_iter=500)\n",
    "\n",
    "evaluate_regression_model(reg, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
